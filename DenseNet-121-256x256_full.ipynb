{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Densenet-121-256x256 - Full\n",
    "\n",
    "This notebook was build to extract features from a DenseNet-121 trained to identify the presence of malign or bening lesions in patches of size 256x256. The patches are subsamples of full size mammographies, as the ones we are using to feed the generative models.\n",
    "\n",
    "The features are extracted at the end of the feature section of DenseNet, before the linear classifier.\n",
    "\n",
    "**Some details of DenseNet-121:**\n",
    "* Four denseblocks with (6, 12, 24, 16)x2 conv layers respectively. The x2 is because it has a Conv1x1 and Conv3x3.\n",
    "* Three transition layers with one conv layer each.\n",
    "* One input and one output layer. (still need to check this)\n",
    "* Final layer count: (6 + 12 + 24 + 16)x2 + 5 = 121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/home/fede/Documents/mhpc/mhpc-thesis/code/breast_cancer_classifier')\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import imageio\n",
    "import os\n",
    "import argparse\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from torchvision import models, transforms\n",
    "from torchvision import transforms, utils\n",
    "from torchvision import datasets\n",
    "\n",
    "import os,sys\n",
    "\n",
    "from mm_patch.data import PatchesDataset\n",
    "import mm_patch.transforms\n",
    "\n",
    "\n",
    "# NYU breast cancer scripts\n",
    "import src.heatmaps.models as models\n",
    "import src.heatmaps.run_producer as run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations to be compatible with Densenet-121 from NYU paper.\n",
    "# Note I am using mean and std as recommended in Pytorch. Maybe calculating the dataset statistics is better.\n",
    "composed = transforms.Compose([ \n",
    "#                                 mm_patch.transforms.ToImage(),\n",
    "                                transforms.ToTensor(),\n",
    "                                mm_patch.transforms.Scale(),\n",
    "                                mm_patch.transforms.GrayToRGB(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_png(file_name):\n",
    "    image = np.array(imageio.imread(file_name)).astype(np.int32)\n",
    "    return image\n",
    "\n",
    "patches = datasets.ImageFolder('../patches_images/test/', transform=composed, target_transform=None, loader=read_image_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.0501, -0.8973, -0.9242,  ...,  0.7228,  0.5163,  0.8369],\n",
       "          [-1.0115, -0.9293, -1.1173,  ...,  0.7027,  0.9932,  0.8286],\n",
       "          [-1.0619, -0.7261, -0.9275,  ...,  0.7379,  0.6255,  0.7715],\n",
       "          ...,\n",
       "          [-1.7703, -1.4850, -1.4497,  ...,  0.5902,  0.2342,  0.0043],\n",
       "          [-1.7502, -1.7636, -1.6344,  ..., -0.0311,  0.2611,  0.5650],\n",
       "          [-1.7552, -1.7066, -1.6982,  ...,  0.3350,  0.3182,  0.2175]],\n",
       " \n",
       "         [[-0.9441, -0.7879, -0.8153,  ...,  0.8684,  0.6573,  0.9851],\n",
       "          [-0.9047, -0.8206, -1.0128,  ...,  0.8478,  1.1448,  0.9765],\n",
       "          [-0.9561, -0.6128, -0.8187,  ...,  0.8838,  0.7689,  0.9182],\n",
       "          ...,\n",
       "          [-1.6804, -1.3887, -1.3526,  ...,  0.7328,  0.3689,  0.1338],\n",
       "          [-1.6598, -1.6735, -1.5414,  ...,  0.0977,  0.3964,  0.7071],\n",
       "          [-1.6650, -1.6152, -1.6066,  ...,  0.4719,  0.4547,  0.3518]],\n",
       " \n",
       "         [[-0.7177, -0.5621, -0.5895,  ...,  1.0868,  0.8766,  1.2029],\n",
       "          [-0.6784, -0.5947, -0.7860,  ...,  1.0663,  1.3619,  1.1944],\n",
       "          [-0.7297, -0.3879, -0.5929,  ...,  1.1021,  0.9877,  1.1363],\n",
       "          ...,\n",
       "          [-1.4507, -1.1603, -1.1244,  ...,  0.9518,  0.5895,  0.3555],\n",
       "          [-1.4302, -1.4439, -1.3123,  ...,  0.3195,  0.6169,  0.9262],\n",
       "          [-1.4353, -1.3858, -1.3772,  ...,  0.6920,  0.6749,  0.5724]]]), 0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set dataset\n",
    "# patches = PatchesDataset(data_path='./patches_256x256.pkl', transform = composed)\n",
    "\n",
    "# Dataloader parameters\n",
    "batch_size = 4\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(patches)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "# this train loader is to have random access\n",
    "loader = torch.utils.data.DataLoader(patches, batch_size=batch_size, \n",
    "                                            num_workers=4)\n",
    "train_loader = torch.utils.data.DataLoader(patches, batch_size=batch_size, \n",
    "                                           sampler=train_sampler, num_workers=4)\n",
    "validation_loader = torch.utils.data.DataLoader(patches, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Densenet-121 Model \n",
    "We have to load the model parameters from the NYU breast_cancer_classifier github: \n",
    "'./models/sample_patch_model.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {}\n",
    "\n",
    "parameters['device_type'] = \"cpu\"\n",
    "parameters['gpu_number'] = 0\n",
    "# number of classes of Densenet classifier (it is not the same as dense/venous!)\n",
    "parameters['number_of_classes'] = 4\n",
    "parameters['initial_parameters'] = '/home/fede/Documents/mhpc/mhpc-thesis/code/breast_cancer_classifier/models/sample_patch_model.p'\n",
    "\n",
    "model, device = run.load_model(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# # summary(your_model, input_size=(channels, H, W))\n",
    "# summary(model, input_size=(3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easy way of checking layer names (you have to be careful because names are not exactly the same)\n",
    "# model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 256, 256])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(loader))\n",
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get activations\n",
    "def get_activation(layer_dict, name):\n",
    "    \"\"\"\n",
    "    Define hook to extract intermediate layer features\n",
    "    \"\"\"\n",
    "    def hook(model, input, output):\n",
    "        layer_dict[name].append(output.detach())\n",
    "        # layer_dict[name] = torch.cat(layer_dict[name], output.detach())\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register hook\n",
    "activations = {'norm5': []}\n",
    "handle_linear = model.densenet.features.norm5.register_forward_hook(get_activation(activations, 'norm5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:00<00:02,  1.99it/s]\u001b[A\n",
      " 40%|████      | 2/5 [00:00<00:01,  2.20it/s]\u001b[A\n",
      " 60%|██████    | 3/5 [00:01<00:00,  2.38it/s]\u001b[A\n",
      " 80%|████████  | 4/5 [00:01<00:00,  2.50it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.46it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm as tqdm\n",
    "with torch.no_grad():\n",
    "#     output = [(densenet(batch['patch']), batch['target']) for batch in loader]\n",
    "        output = [F.softmax(model(torch.FloatTensor(batch[0]).to(device)), dim=1).cpu().detach().numpy() \n",
    "                  for batch in tqdm(loader)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intrinsic Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/home/fede/Documents/mhpc/mhpc-thesis/code/TWO-NN')\n",
    "import id2nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation before linear classifier (ED = 1024)\n",
    "\n",
    "To get the activation before the linear classifier we have to take the output of densenet.feature, activations\\['norm5'\\], and apply an F.adaptive_avg_pool2d + a flatten operation.\n",
    "\n",
    "In numbers:\n",
    "\n",
    "```\n",
    "activation['norm5'] = (n_batch, 1024, 8, 8)\n",
    "F.adaptive_avg_pool2d(out_batch, (1, 1)).view(n_batch, -1) = (n_batch, 1024)\n",
    "```\n",
    "Thus the input of the classifier is of dimension 1024.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ F.adaptive_avg_pool2d(out_batch, (1, 1)).view(4, -1) for out_batch in activations['norm5'] ] \n",
    "# we concatenate all the batches\n",
    "features = torch.cat(features, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "blocks_dim, blocks_dim_std, blocks_size, d_mat2 = id2nn.two_nn_block_analysis(features.numpy(), .9, shuffle = True)\n",
    "\n",
    "# file_path = './activations_alexnet/block_analysis_linear.txt'\n",
    "# with open(file_path, 'wb') as file: \n",
    "#     np.savetxt(file, np.array(blocks_dim))\n",
    "#     np.savetxt(file, np.array(blocks_dim_std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(blocks_size, blocks_dim, \"r.-\")\n",
    "plt.errorbar(blocks_size, blocks_dim, fmt = \"r.-\", yerr = np.array(blocks_dim_std))\n",
    "plt.xlabel('block size')\n",
    "plt.ylabel('intrinsic dimension')\n",
    "plt.title('Before classifier [ED = 1024]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID for input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build data into single numpy array\n",
    "input_data = []\n",
    "for row in patches.data['patch']:\n",
    "    row = np.array(row)\n",
    "#     print(type(row))\n",
    "#     print(row)\n",
    "    input_data.append(row.flatten(-1))\n",
    "    \n",
    "input_data = np.asarray(input_data)\n",
    "input_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate id\n",
    "blocks_dim_input, blocks_dim_std_input, blocks_size_input, _ = id2nn.two_nn_block_analysis(input_data, .9, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(blocks_size_input, blocks_dim_input, fmt = \"r.-\", yerr = np.array(blocks_dim_std_input))\n",
    "plt.xlabel('block size')\n",
    "plt.ylabel('intrinsic dimension')\n",
    "plt.title('Input data [ED = 256*256]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "from numpy import cov\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = features.numpy()\n",
    "\n",
    "print(f'features shape before{x.shape}')\n",
    "# define scaler instance\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "\n",
    "print(features.shape)\n",
    "# features_ts = scaler.fit_transform(features)\n",
    "x_centered = x - np.mean(x, axis=0)\n",
    "\n",
    "\n",
    "# Own implementation (stability error)\n",
    "# cov_mat = cov(x_centered.T)\n",
    "# print(cov_mat.shape)\n",
    "\n",
    "# # Calculate Eigenvectors and Eigenvalues\n",
    "# w, v = LA.eig(cov_mat)\n",
    "# print(\"w:\", w)\n",
    "# # print(\"v:\", v)\n",
    "\n",
    "\n",
    "# Using scipy package\n",
    "\n",
    "\n",
    "# percentage of variance explained\n",
    "# can also use: PCA(n_components=2)\n",
    "pca = PCA(n_components=0.95)\n",
    "x_centered = pca.fit_transform(x_centered)\n",
    "# pca.explained_variance_ are the eigenvalues\n",
    "eigenvalues = pca.explained_variance_ \n",
    "print(len(eigenvalues))\n",
    "# pca.components_ are the eigenvectors\n",
    "# print(pca.components_[1,:])\n",
    "\n",
    "print(f'features shape after{x_centered.shape}')\n",
    "\n",
    "# Plot eigenvalues \n",
    "plt.plot(np.log(eigenvalues), '.')\n",
    "plt.ylabel('Eigenvalue $(\\lambda)$')\n",
    "plt.xlabel('$\\lambda$ number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(features.shape)\n",
    "file_path = './activations_densenet/features_pca_0.95_256x256.txt'\n",
    "with open(file_path, 'w') as file: \n",
    "    np.savetxt(file, x_centered)\n",
    "\n",
    "features = 0\n",
    "x = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20,20))\n",
    "plt.plot(x_centered[:,0],x_centered[:,1], '.')\n",
    "x_centered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "x_embedded = TSNE(n_components=2, perplexity = 100).fit_transform(x_centered)\n",
    "x_embedded.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(x_embedded[:,0],x_embedded[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(features.shape)\n",
    "# file_path = './activations_densenet/before_classification.txt'\n",
    "# with open(file_path, 'w') as file: \n",
    "#     np.savetxt(file, features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(features.shape)\n",
    "file_path = './activations_densenet/features_pca_0.95_256x256.txt'\n",
    "with open(file_path, 'r') as file: \n",
    "    X = np.loadtxt(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2).fit(X)\n",
    "plt.scatter(X[:,0], X[:,1], c = kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  patches.data['patch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patches = 40\n",
    "cluster = 0\n",
    "fig = plt.figure(figsize = (20,30))\n",
    "cols = 5\n",
    "rows = num_patches//cols + 1\n",
    "for i,patch in enumerate(data[kmeans.labels_ == cluster][:num_patches]):\n",
    "    ax = fig.add_subplot(rows, cols, i+1)\n",
    "    ax.imshow(patch)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
